{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# Suppress TensorFlow warnings for clarity\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.1),  # Rotates images by a factor between -10% and +10%\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "labels_df = pd.read_csv('/Users/angel/OneDrive/Desktop/CS 4100/Satellite_Image_Classifier/data/train_v2.csv')\n",
    "labels_df.head()\n",
    "\n",
    "# Print all unique tags\n",
    "# from itertools import chain\n",
    "labels_list = list(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values]))\n",
    "labels_set = set(labels_list)\n",
    "\n",
    "images_title = [labels_df[labels_df['tags'].str.contains(label)].iloc[i]['image_name'] + '.jpg' \n",
    "                for i, label in enumerate(labels_set)]\n",
    "\n",
    "# plt.rc('axes', grid=False)\n",
    "# _, axs = plt.subplots(5, 4, sharex='col', sharey='row', figsize=(15, 20))\n",
    "# axs = axs.ravel()\n",
    "\n",
    "# for i, (image_name, label) in enumerate(zip(images_title, labels_set)):\n",
    "#     img = mpimg.imread('/Users/angel/OneDrive/Desktop/CS 4100/train-jpg/train-jpg' + '/' + image_name)\n",
    "#     axs[i].imshow(img)\n",
    "#     axs[i].set_title('{} - {}'.format(image_name, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jpeg_dir = '/Users/angel/OneDrive/Desktop/CS 4100/train-jpg/train-jpg'\n",
    "train_csv_file = '/Users/angel/OneDrive/Desktop/CS 4100/Satellite_Image_Classifier/data/train_v2.csv'\n",
    "test_jpeg_dir = '/Users/angel/OneDrive/Desktop/CS 4100/test-jpg/test-jpg'\n",
    "test_additional_jpeg_dir = '/Users/angel/OneDrive/Desktop/CS 4100/Satellite_Image_Classifier/data/test_v2_file_mapping.csv'\n",
    "img_resize = (128, 128)  # Desired image size\n",
    "validation_split = 0.2\n",
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Step 1: Read Labels and File Paths\n",
    "labels_df = pd.read_csv(train_csv_file)\n",
    "\n",
    "# Step 2: Extract all unique labels\n",
    "labels = sorted(set(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values])))\n",
    "\n",
    "# Step 3: Create a mapping from label to index\n",
    "labels_map = {label: idx for idx, label in enumerate(labels)}\n",
    "num_classes = len(labels_map)\n",
    "\n",
    "# Step 4: Map Labels to Integers and One-Hot Encode\n",
    "def encode_tags(tags_str):\n",
    "    tags = tags_str.split(' ')\n",
    "    targets = np.zeros(num_classes, dtype='float32')\n",
    "    for tag in tags:\n",
    "        targets[labels_map[tag]] = 1.0\n",
    "    return targets\n",
    "\n",
    "labels_df['targets'] = labels_df['tags'].apply(encode_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32383 8096\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Split Data into Training and Validation Sets\n",
    "train_df, val_df = train_test_split(labels_df, test_size=validation_split, random_state=42)\n",
    "\n",
    "# Reset indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define the Pure Python Image Loading Function\n",
    "def _load_image(path_str):\n",
    "    \"\"\"\n",
    "    Load and preprocess an image from a given file path.\n",
    "\n",
    "    Args:\n",
    "        path_str (bytes): The file path as a bytes object.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed image as a NumPy array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from PIL import Image  # Import inside the function to ensure accessibility\n",
    "\n",
    "        # Decode the bytes to a UTF-8 string\n",
    "        path_str = path_str.decode('utf-8')\n",
    "\n",
    "        # Open the image using PIL\n",
    "        with Image.open(path_str) as img:\n",
    "            # Convert image to RGB (handles CMYK and other modes)\n",
    "            img = img.convert('RGB')\n",
    "            # Resize the image\n",
    "            img = img.resize(img_resize)\n",
    "            # Convert to NumPy array and normalize to [0, 1]\n",
    "            img_array = np.array(img).astype(np.float32) / 255.0\n",
    "            # Normalize to [-1, 1]\n",
    "            img_array = (img_array * 2.0) - 1.0\n",
    "\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path_str}: {e}\")\n",
    "        # Return a zero tensor as a placeholder to prevent pipeline failure\n",
    "        return np.zeros([img_resize[0], img_resize[1], 3], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Define the TensorFlow Wrapper Function using tf.numpy_function\n",
    "def load_and_preprocess_image_numpy(path, label):\n",
    "    \"\"\"\n",
    "    TensorFlow wrapper for loading and preprocessing an image using tf.numpy_function.\n",
    "\n",
    "    Args:\n",
    "        path (tf.Tensor): The file path as a TensorFlow string tensor.\n",
    "        label (tf.Tensor): The corresponding label tensor.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of the preprocessed image tensor and label tensor.\n",
    "    \"\"\"\n",
    "    # Use tf.numpy_function to apply the pure Python _load_image function\n",
    "    image = tf.numpy_function(func=_load_image, inp=[path], Tout=tf.float32)\n",
    "\n",
    "    # Set the shape of the image tensor\n",
    "    image.set_shape([img_resize[0], img_resize[1], 3])\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, label):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to the image.\n",
    "    \n",
    "    Args:\n",
    "        image (tf.Tensor): The input image tensor.\n",
    "        label (tf.Tensor): The corresponding label tensor.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: The augmented image tensor and the original label tensor.\n",
    "    \"\"\"\n",
    "    image = data_augmentation(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Define the Dataset Creation Function using tf.numpy_function\n",
    "def create_dataset_numpy(df, training=True):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow dataset from a DataFrame using tf.numpy_function.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing image paths and labels.\n",
    "        training (bool): Whether the dataset is for training (enables shuffling).\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: The prepared dataset.\n",
    "    \"\"\"\n",
    "    # Construct full file paths\n",
    "    image_paths = df['image_name'].apply(lambda x: os.path.join(train_jpeg_dir, f\"{x}.jpg\")).tolist()\n",
    "    labels = np.stack(df['targets'].values)\n",
    "\n",
    "    # Create a TensorFlow Dataset from the file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "\n",
    "    # Map the load_and_preprocess_image_numpy function to the dataset\n",
    "    dataset = dataset.map(load_and_preprocess_image_numpy, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if training:\n",
    "        # Shuffle the dataset for training\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "        # Apply data augmentation\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # Batch and prefetch the dataset for optimal performance\n",
    "    dataset = dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying Training Dataset with tf.numpy_function:\n",
      "Image tensor shape: (32, 128, 128, 3)\n",
      "Image tensor dtype: <dtype: 'float32'>\n",
      "Image tensor min value: -0.9707219\n",
      "Image tensor max value: 0.8028034\n",
      "Image tensor mean value: -0.37111065\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Create Training and Validation Datasets using tf.numpy_function\n",
    "train_dataset_numpy = create_dataset_numpy(train_df, training=True)\n",
    "val_dataset_numpy = create_dataset_numpy(val_df, training=False)\n",
    "\n",
    "#print(len(train_dataset_numpy),len (val_dataset_numpy))\n",
    "\n",
    "# Step 10: Verify the Datasets\n",
    "print(\"\\nVerifying Training Dataset with tf.numpy_function:\")\n",
    "for images, labels in train_dataset_numpy.take(1):\n",
    "    print(\"Image tensor shape:\", images.shape)\n",
    "    print(\"Image tensor dtype:\", images.dtype)\n",
    "    print(\"Image tensor min value:\", tf.reduce_min(images).numpy())\n",
    "    print(\"Image tensor max value:\", tf.reduce_max(images).numpy())\n",
    "    print(\"Image tensor mean value:\", tf.reduce_mean(images).numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40669\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 12: Create Test Dataset using tf.numpy_function and PIL-based Loader\n",
    "def load_and_preprocess_test_image_numpy(path):\n",
    "    \"\"\"\n",
    "    TensorFlow wrapper for loading and preprocessing test images using tf.numpy_function.\n",
    "\n",
    "    Args:\n",
    "        path (tf.Tensor): The file path as a TensorFlow string tensor.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The preprocessed image tensor.\n",
    "    \"\"\"\n",
    "    # Use tf.numpy_function to apply the pure Python _load_image function\n",
    "    image = tf.numpy_function(func=_load_image, inp=[path], Tout=tf.float32)\n",
    "\n",
    "    # Set the shape of the image tensor\n",
    "    image.set_shape([img_resize[0], img_resize[1], 3])\n",
    "\n",
    "    return image\n",
    "\n",
    "# Get test file paths\n",
    "test_files = [os.path.join(test_jpeg_dir, f) for f in os.listdir(test_jpeg_dir)]\n",
    "\n",
    "print(len(test_files))\n",
    "\n",
    "# Create test dataset using the PIL-based loader\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "test_dataset = test_dataset.map(load_and_preprocess_test_image_numpy, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "# (Optional) Visualize Test Images Without Labels\n",
    "num_test_images_to_display = 9\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for images in test_dataset.take(1):\n",
    "    test_images_np = images.numpy()\n",
    "\n",
    "    # Convert images from [-1, 1] to [0, 1] for visualization\n",
    "    test_images_np = (test_images_np + 1.0) / 2.0\n",
    "    break\n",
    "\n",
    "print(len(test_images_np))\n",
    "\n",
    "# for i in range(num_test_images_to_display):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(test_images_np[i])\n",
    "#     plt.axis(\"off\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images (x): (8096, 128, 128, 3)\n",
      "All labels (y): (8096, 17)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Convert dataset into numpy arrays\n",
    "x_train_data = []\n",
    "y_train_data = []\n",
    "\n",
    "x_test_data = []\n",
    "y_test_data = []\n",
    "\n",
    "for x_batch, y_batch in train_dataset_numpy:\n",
    "    x_train_data.append(x_batch.numpy())  # Add images to list\n",
    "    y_train_data.append(y_batch.numpy())  # Add labels to list\n",
    "\n",
    "for x_batch, y_batch in val_dataset_numpy:\n",
    "    x_test_data.append(x_batch.numpy())  # Add images to list\n",
    "    y_test_data.append(y_batch.numpy())  # Add labels to list\n",
    "\n",
    "# Concatenate to get all data\n",
    "x_train_data = np.concatenate(x_train_data, axis=0)\n",
    "y_train_data = np.concatenate(y_train_data, axis=0)\n",
    "x_test_data = np.concatenate(x_test_data, axis=0)\n",
    "y_test_data = np.concatenate(y_test_data, axis=0)\n",
    "\n",
    "print(\"All images (x):\", x_test_data.shape)\n",
    "print(\"All labels (y):\", y_test_data.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 82ms/step - accuracy: 0.0487 - loss: 0.2157 - val_accuracy: 0.0594 - val_loss: 0.1662\n",
      "Epoch 2/6\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 88ms/step - accuracy: 0.0806 - loss: 0.1541 - val_accuracy: 0.0662 - val_loss: 0.1494\n",
      "Epoch 3/6\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 88ms/step - accuracy: 0.0838 - loss: 0.1370 - val_accuracy: 0.0933 - val_loss: 0.1435\n",
      "Epoch 4/6\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 88ms/step - accuracy: 0.0897 - loss: 0.1213 - val_accuracy: 0.0721 - val_loss: 0.1407\n",
      "Epoch 5/6\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 90ms/step - accuracy: 0.0934 - loss: 0.1063 - val_accuracy: 0.0914 - val_loss: 0.1467\n",
      "Epoch 6/6\n",
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 112ms/step - accuracy: 0.0930 - loss: 0.0899 - val_accuracy: 0.0919 - val_loss: 0.1603\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      agriculture       0.77      0.74      0.76      2441\n",
      "   artisinal_mine       0.49      0.33      0.39        70\n",
      "      bare_ground       0.33      0.05      0.08       175\n",
      "         blooming       0.00      0.00      0.00        64\n",
      "        blow_down       0.00      0.00      0.00        25\n",
      "            clear       0.95      0.96      0.95      5728\n",
      "           cloudy       0.87      0.69      0.77       395\n",
      "conventional_mine       0.00      0.00      0.00        22\n",
      "      cultivation       0.50      0.14      0.22       864\n",
      "       habitation       0.49      0.49      0.49       743\n",
      "             haze       0.71      0.58      0.64       533\n",
      "    partly_cloudy       0.87      0.86      0.87      1440\n",
      "          primary       0.97      0.99      0.98      7507\n",
      "             road       0.65      0.80      0.72      1568\n",
      "selective_logging       0.20      0.11      0.15        61\n",
      "       slash_burn       0.00      0.00      0.00        47\n",
      "            water       0.62      0.40      0.49      1459\n",
      "\n",
      "        micro avg       0.86      0.82      0.84     23142\n",
      "        macro avg       0.50      0.42      0.44     23142\n",
      "     weighted avg       0.84      0.82      0.82     23142\n",
      "      samples avg       0.89      0.85      0.86     23142\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      agriculture       0.77      0.74      0.76      2441\n",
      "   artisinal_mine       0.37      0.44      0.41        70\n",
      "      bare_ground       0.33      0.16      0.22       175\n",
      "         blooming       0.09      0.05      0.06        64\n",
      "        blow_down       0.00      0.00      0.00        25\n",
      "            clear       0.95      0.96      0.95      5728\n",
      "           cloudy       0.83      0.74      0.78       395\n",
      "conventional_mine       0.23      0.14      0.17        22\n",
      "      cultivation       0.46      0.20      0.28       864\n",
      "       habitation       0.47      0.55      0.51       743\n",
      "             haze       0.67      0.66      0.66       533\n",
      "    partly_cloudy       0.87      0.86      0.87      1440\n",
      "          primary       0.97      0.99      0.98      7507\n",
      "             road       0.65      0.80      0.72      1568\n",
      "selective_logging       0.13      0.18      0.15        61\n",
      "       slash_burn       0.03      0.02      0.03        47\n",
      "            water       0.62      0.40      0.49      1459\n",
      "\n",
      "        micro avg       0.85      0.83      0.84     23142\n",
      "        macro avg       0.50      0.46      0.47     23142\n",
      "     weighted avg       0.83      0.83      0.83     23142\n",
      "      samples avg       0.88      0.86      0.86     23142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\angel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(y_test_data[0])\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_resize[0], img_resize[1], 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='sigmoid')  # Use the number of unique classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_data, y_train_data, epochs=6, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "\n",
    "#predictions = model.predict(x_test_data)\n",
    "#predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# accuracy = accuracy_score(predicted_classes, y_train_data)\n",
    "\n",
    "# print(f\"Test accuracy: {accuracy}\")\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_prob = model.predict(x_test_data)\n",
    "\n",
    "thresholds = [0.5, 0.2, 0.3, 0.2, 0.2, .5, .4, .2, .4, .4, .4,  .5, .5, .5, .2, .2, .5]  # Custom threshold for each class\n",
    "predicted_classes = np.array([pred > threshold for pred, threshold in zip(y_pred_prob.T, thresholds)]).T.astype(int)\n",
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Threshold probabilities at 0.5\n",
    "\n",
    "# Flatten the test labels for comparison\n",
    "print(classification_report(y_test_data, y_pred, target_names=labels_map))\n",
    "\n",
    "print(classification_report(y_test_data, predicted_classes, target_names=labels_map))\n",
    "\n",
    "# Example of printing a prediction\n",
    "# for i in range(5):  # Print first 5 predictions\n",
    "#     print(f\"Predicted class for test image {i}: {predicted_classes[i]} (Actual class: {y_train_data[i]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
